{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP0DSTQkl00in9thRRavSaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malmong/nvidia-healthcare-assistant/blob/main/nvidia_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries and Dependencies for AI Model Integration"
      ],
      "metadata": {
        "id": "aHONbiC_7a1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install OpenAI\n",
        "!pip install requests\n",
        "!pip install PyMuPDF\n",
        "!pip install --upgrade --quiet llama-index-llms-nvidia llama-index-embeddings-nvidia llama-index-readers-file\n",
        "!pip install llama-index-core\n",
        "!pip install llama-index-readers-file\n",
        "!pip install llama-index-llms-nvidia\n",
        "!pip install llama-index-embeddings-nvidia\n",
        "!pip install llama-index-postprocessor-nvidia-rerank\n",
        "!pip install llama-parse\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMpeWono7iRL",
        "outputId": "62188816-5bc0-4f2c-cd4c-57b7408a1ac9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: OpenAI in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.23.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload medical report PDF Files and Save"
      ],
      "metadata": {
        "id": "hpAO6EWo5Oc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def upload_pdf_files():\n",
        "    count = 1  # Counter for file names\n",
        "\n",
        "    while True:\n",
        "        # Upload a file\n",
        "        print(\"Upload a PDF file (or click 'Stop' to end):\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Check if the upload was canceled\n",
        "        if not uploaded:\n",
        "            print(\"Upload stopped.\")\n",
        "            break\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            if filename.endswith('.pdf'):  # Check if the file is a PDF\n",
        "                # Assign a unique file name\n",
        "                new_filename = f'/content/medical_report{count}.pdf'\n",
        "                os.rename(filename, new_filename)\n",
        "                print(f\"File has been saved as: {new_filename}\")\n",
        "                count += 1  # Increment the count for the next file name\n",
        "            else:\n",
        "                print(f\"The uploaded file is not a PDF. Skipping.\")\n"
      ],
      "metadata": {
        "id": "tB-A8PhLS2YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capture Photo Using Webcam and Save as File"
      ],
      "metadata": {
        "id": "ia2scgdZ3o8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# Python take_photo function\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  # Start writing JavaScript\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "\n",
        "      // Create a div element\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      // Create a button element\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      // Create a video element\n",
        "      const video = document.createElement('video');\n",
        "      // Set the video style to display as a block\n",
        "      video.style.display = 'block';\n",
        "      // Access the camera (webcam)\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      // Add div as a child element to the body\n",
        "      document.body.appendChild(div);\n",
        "      // Add video to the div\n",
        "      div.appendChild(video);\n",
        "      // Connect video with the webcam stream\n",
        "      video.srcObject = stream;\n",
        "      // Await to play the video asynchronously (related to threads) (async with await)\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for the Capture button to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      // Create a canvas element\n",
        "      const canvas = document.createElement('canvas');\n",
        "      // Set the canvas size\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      // Draw the video frame on the canvas\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      // Stop the video stream\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      // Remove the div element\n",
        "      div.remove();\n",
        "      // Return the image as a base64-encoded string\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  # Execute the JavaScript and return the result to Python (basically this)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # The data is saved in base64 format in the browser, so decode it\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  # Save the binary data to a file\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n"
      ],
      "metadata": {
        "id": "wGl0-o_Y3oke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Label Extraction and Asset Upload with NVCF API"
      ],
      "metadata": {
        "id": "YNF13E475S1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import zipfile\n",
        "import requests\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "# NVAI endpoint for the ocdrnet NIM\n",
        "nvai_url = \"https://ai.api.nvidia.com/v1/cv/nvidia/ocdrnet\"\n",
        "\n",
        "header_auth = f\"Bearer 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\"\n",
        "\n",
        "def _upload_asset(input, description):\n",
        "    \"\"\"\n",
        "    Uploads an asset to the NVCF API.\n",
        "    :param input: The binary asset to upload\n",
        "    :param description: A description of the asset\n",
        "    \"\"\"\n",
        "    assets_url = \"https://api.nvcf.nvidia.com/v2/nvcf/assets\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": header_auth,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"accept\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    s3_headers = {\n",
        "        \"x-amz-meta-nvcf-asset-description\": description,\n",
        "        \"content-type\": \"image/jpg\",\n",
        "    }\n",
        "\n",
        "    payload = {\"contentType\": \"image/jpg\", \"description\": description}\n",
        "\n",
        "    response = requests.post(assets_url, headers=headers, json=payload, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    asset_url = response.json()[\"uploadUrl\"]\n",
        "    asset_id = response.json()[\"assetId\"]\n",
        "\n",
        "    response = requests.put(asset_url, data=input, headers=s3_headers, timeout=300)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    return uuid.UUID(asset_id)\n",
        "\n",
        "def clear_output_directory(directory):\n",
        "    \"\"\"Clears all files from the output directory.\"\"\"\n",
        "    if os.path.exists(directory):\n",
        "        for filename in os.listdir(directory):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.remove(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "def extract_labels_from_image(image_path: str, output_dir: str = \"output_directory\") -> list:\n",
        "    \"\"\"\n",
        "    Processes an image, uploads it to the NVCF API, and extracts labels from the response.\n",
        "\n",
        "    :param image_path: The file path of the image to process.\n",
        "    :param output_dir: The directory to store the output files.\n",
        "    :return: A list of extracted labels.\n",
        "    \"\"\"\n",
        "    # Clear all files in the output directory\n",
        "    clear_output_directory(output_dir)\n",
        "\n",
        "    # Image upload\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        asset_id = _upload_asset(img_file, \"Input Image\")\n",
        "\n",
        "    inputs = {\"image\": f\"{asset_id}\", \"render_label\": True}\n",
        "    asset_list = f\"{asset_id}\"\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"NVCF-INPUT-ASSET-REFERENCES\": asset_list,\n",
        "        \"NVCF-FUNCTION-ASSET-IDS\": asset_list,\n",
        "        \"Authorization\": header_auth,\n",
        "    }\n",
        "\n",
        "    # API request\n",
        "    response = requests.post(nvai_url, headers=headers, json=inputs)\n",
        "\n",
        "    # Save and extract the zip file containing the results\n",
        "    output_zip = f\"{output_dir}.zip\"\n",
        "    with open(output_zip, \"wb\") as out:\n",
        "        out.write(response.content)\n",
        "\n",
        "    with zipfile.ZipFile(output_zip, \"r\") as z:\n",
        "        z.extractall(output_dir)\n",
        "\n",
        "    output_files = os.listdir(output_dir)\n",
        "\n",
        "    # All responses in .response files\n",
        "    all_responses = []  # List to store each response data\n",
        "\n",
        "    for file_name in output_files:\n",
        "        if file_name.endswith(\".response\"):\n",
        "            response_file_path = os.path.join(output_dir, file_name)\n",
        "            with open(response_file_path, \"r\") as response_file:\n",
        "                try:\n",
        "                    response_data = json.load(response_file)  # Parse JSON content\n",
        "                    all_responses.append({\"file\": file_name, \"content\": response_data})\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"{file_name} is not a valid JSON file.\")\n",
        "\n",
        "    result_json = json.dumps(all_responses, indent=4)\n",
        "    result_data = json.loads(result_json)\n",
        "\n",
        "    # Extract labels from the responses\n",
        "    labels = []\n",
        "    for response_item in result_data:\n",
        "        content = response_item.get(\"content\")  # Access 'content' key\n",
        "        if content and \"metadata\" in content:\n",
        "            for item in content[\"metadata\"]:\n",
        "                if \"label\" in item:\n",
        "                    labels.append(item[\"label\"])\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "a9_hxa1j7ZwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pdf reader"
      ],
      "metadata": {
        "id": "Vo6EUpnhHcEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Function for Allergy Skin Test Results Chart PDF to text\n",
        "def pdf_to_text(pdf_path):\n",
        "    \"\"\"\n",
        "    Converts a PDF file to text.\n",
        "    :param pdf_path: The path to the PDF file.\n",
        "    :return: A string containing the extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def convert_pdf_to_documents(pdf_path):\n",
        "    \"\"\"\n",
        "    Converts a PDF file to a list of documents containing text.\n",
        "    :param pdf_path: The path to the PDF file.\n",
        "    :return: A list of dictionaries with the key 'text' containing the PDF content.\n",
        "    \"\"\"\n",
        "    # Convert PDF to text\n",
        "    pdf_text = pdf_to_text(pdf_path)\n",
        "\n",
        "    # Return the text as a document\n",
        "    documents = [{\"text\": pdf_text}]\n",
        "    return documents\n"
      ],
      "metadata": {
        "id": "JUFmT1mQUD79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Food Consumption Recommendation Based on Documents and Labels"
      ],
      "metadata": {
        "id": "jDcZRWfsHMCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "from llama_index.llms.nvidia import NVIDIA\n",
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "\n",
        "# Define the recommend_food_based_on_labels function\n",
        "def recommend_food_based_on_labels(documents, labels):\n",
        "    \"\"\"\n",
        "    This function provides a recommendation for food consumption based on the given documents and labels.\n",
        "    It returns only the conclusion.\n",
        "    \"\"\"\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    # Set the NVIDIA API key\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
        "\n",
        "    # Initialize the model\n",
        "    llm = NVIDIA(model=\"nvidia/llama-3.1-nemotron-70b-instruct\")\n",
        "\n",
        "    # Create the message\n",
        "    messages = [\n",
        "        ChatMessage(\n",
        "            role=MessageRole.SYSTEM, content=(\"You are a doctor.\")\n",
        "        ),\n",
        "        ChatMessage(\n",
        "            role=MessageRole.USER,\n",
        "            content=(f\"Based on the following documents {documents}, tell me whether consuming food containing {labels} is recommended.\"),\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    # Send the message to the model and get a response\n",
        "    response = llm.chat(messages)\n",
        "\n",
        "    # Extract only the conclusion from the response\n",
        "    if response and response.message:\n",
        "        conclusion = response.message.content.split(\"\\n\")[-1]  # Extract the last line as the conclusion\n",
        "        return response\n",
        "    else:\n",
        "        return \"No response received.\"\n"
      ],
      "metadata": {
        "id": "bTbxlhalPZxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing Food Consumption Recommendations Based on Medical Reports"
      ],
      "metadata": {
        "id": "ts3cpq_IAjvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_food_based_on_labels_last(all_recommendations):\n",
        "    \"\"\"\n",
        "    This function takes the recommendations from multiple documents and processes them to return\n",
        "    a summary of food recommendations in a dictionary format.\n",
        "    \"\"\"\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    # Set the NVIDIA API key\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
        "\n",
        "    # Initialize the model\n",
        "    llm = NVIDIA(model=\"nvidia/llama-3.1-nemotron-70b-instruct\")\n",
        "\n",
        "    # Initialize the dictionary to store results\n",
        "    recommendations_summary = {}\n",
        "\n",
        "    for pdf_file, recommendation in all_recommendations.items():\n",
        "        # Create the message\n",
        "        messages = [\n",
        "            ChatMessage(\n",
        "                role=MessageRole.SYSTEM, content=(\"You are a doctor.\")\n",
        "            ),\n",
        "            ChatMessage(\n",
        "                role=MessageRole.USER,\n",
        "                content=(f\"{recommendation}\\nThis text is an evaluation of the food I plan to consume, based on my medical report. \"\n",
        "                         \"Summarize whether it is good or bad for my health in three lines, based on all the PDFs. \"\n",
        "                         \"If there is no relevant information, it's okay to consume the food.\"),\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        # Send the message to the model and get a response\n",
        "        response = llm.chat(messages)\n",
        "\n",
        "        # Extract only the conclusion from the response\n",
        "        if response and response.message:\n",
        "            conclusion = response.message.content.split(\"\\n\")[-1]  # Extract the last line as the conclusion\n",
        "            recommendations_summary[pdf_file] = conclusion\n",
        "        else:\n",
        "            recommendations_summary[pdf_file] = \"Unable to receive a response.\"\n",
        "\n",
        "    return recommendations_summary\n"
      ],
      "metadata": {
        "id": "zq6fkRDamYEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main code"
      ],
      "metadata": {
        "id": "An1DiXqi3Lig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image\n",
        "\n",
        "# Directory path where the PDF files are stored\n",
        "pdf_directory = '/content/'\n",
        "\n",
        "# Get a list of all PDF files starting with 'medical_report'\n",
        "pdf_files = sorted([f for f in os.listdir(pdf_directory) if f.startswith('medical_report') and f.endswith('.pdf')])\n",
        "\n",
        "# Function to determine the next available report filename\n",
        "def get_next_report_filename():\n",
        "    if not pdf_files:\n",
        "        return 'medical_report1.pdf'  # If no files exist, return the first file name\n",
        "    else:\n",
        "        # Find the highest number in the existing files and calculate the next number\n",
        "        existing_numbers = [int(f.split('medical_report')[1].split('.pdf')[0]) for f in pdf_files]\n",
        "        next_number = max(existing_numbers) + 1\n",
        "        return f'medical_report{next_number}.pdf'\n",
        "\n",
        "# If PDF files exist, ask whether to upload additional files\n",
        "if pdf_files:\n",
        "    print(f\"Existing PDF files: {pdf_files}\")\n",
        "    user_choice = input(\"Do you want to upload additional PDF files? (yes/no): \").strip().lower()\n",
        "    if user_choice == 'yes':\n",
        "        uploaded_files = files.upload()  # Upload new files\n",
        "        for filename in uploaded_files.keys():\n",
        "            if filename.endswith('.pdf'):\n",
        "                new_filename = os.path.join(pdf_directory, get_next_report_filename())\n",
        "                os.rename(filename, new_filename)\n",
        "                pdf_files.append(new_filename)\n",
        "                print(f\"File has been saved as: {new_filename}\")\n",
        "    elif user_choice == 'no':\n",
        "        print(\"Proceeding with existing PDF files.\")\n",
        "    else:\n",
        "        print(\"Invalid input. Proceeding with existing PDF files.\")\n",
        "\n",
        "# If no PDF files exist, prompt the user to upload files\n",
        "else:\n",
        "    print(\"No PDF files found. Please upload the PDF files.\")\n",
        "    upload_pdf_files()\n",
        "    # After uploading, refresh the list of PDF files\n",
        "    pdf_files = sorted([f for f in os.listdir(pdf_directory) if f.startswith('medical_report') and f.endswith('.pdf')])\n",
        "\n",
        "# Initialize the variable to accumulate recommendations\n",
        "all_recommendations = {}\n",
        "\n",
        "try:\n",
        "\n",
        "    # Take a photo\n",
        "    filename = take_photo()\n",
        "    print('Saved to {}'.format(filename))\n",
        "\n",
        "    # Display the taken photo\n",
        "    display(Image(filename))\n",
        "\n",
        "\n",
        "    # Set the image path\n",
        "    image_path = \"/content/photo.jpg\"\n",
        "\n",
        "    # Extract labels from the image\n",
        "    labels = extract_labels_from_image(image_path)\n",
        "\n",
        "    # Generate recommendations for each PDF file\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
        "        print(f\"\\nProcessing {pdf_file}...\")\n",
        "\n",
        "        # Convert PDF file to documents\n",
        "        documents = convert_pdf_to_documents(pdf_path)\n",
        "\n",
        "        # Generate recommendations based on labels\n",
        "        recommendation = recommend_food_based_on_labels(documents, labels)\n",
        "\n",
        "        # Accumulate recommendations\n",
        "        all_recommendations[pdf_file] = recommendation\n",
        "\n",
        "        # Each medical report's recommendation\n",
        "        #print(f\"Recommendation for {pdf_file}: {recommendation}\")\n",
        "\n",
        "except Exception as err:\n",
        "    # Display error message if web camera permission is denied or camera is not available\n",
        "    print(str(err))\n",
        "\n",
        "# Process all PDF file recommendations at once using a function\n",
        "try:\n",
        "    # Call the recommend_food_based_on_labels_last function to update all recommendations at once\n",
        "    # This function should return the results as a dictionary.\n",
        "    updated_recommendations = recommend_food_based_on_labels_last(all_recommendations)\n",
        "\n",
        "    # Check if the function returns a dictionary\n",
        "    if isinstance(updated_recommendations, dict):\n",
        "        # Print updated recommendations\n",
        "        print(\"\\nUpdated All Recommendations:\")\n",
        "        for pdf_file, updated_recommendation in updated_recommendations.items():\n",
        "            print(f\"{pdf_file}: {updated_recommendation}\")\n",
        "    else:\n",
        "        print(\"Error: The function did not return a dictionary. Please check the function's implementation.\")\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Error processing recommendations: {str(err)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP--e4kv8ZuM",
        "outputId": "2d5fe1a4-d2ae-4c4a-aaf2-70dec9ef937d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing PDF files: ['medical_report1.pdf', 'medical_report2.pdf']\n",
            "Do you want to upload additional PDF files? (yes/no): ㅜㅐ\n",
            "Invalid input. Proceeding with existing PDF files.\n",
            "\n",
            "Processing medical_report1.pdf...\n",
            "\n",
            "Processing medical_report2.pdf...\n",
            "\n",
            "Updated All Recommendations:\n",
            "medical_report1.pdf: * **DO NOT CONSUME IN CURRENT FORM**: To prevent a potentially life-threatening allergic reaction, avoid the original product altogether.\n",
            "medical_report2.pdf: * **Trans Fat: Avoid Completely** (to mitigate cardiovascular disease risk, given family history and controlled hypertension)\n"
          ]
        }
      ]
    }
  ]
}